---
title: "Bellman Optimality Equation"
date: 2020-01-07
categories: [RL]
tags: [Reinforcement Learning, Theory]
excerpt: "Bellman equation can be defined for opitmal policy. How it looks like?"
mathjax: "true"
order: 9
classes: wide
---

> <span style="color:dodgerblue">**Take away message from the note:**</span>
> * <span style="color:dodgerblue">**Solving a RL task means, roughly, finding a polict that achieves a lot of reward over the long run**</span>
> * <span style="color:dodgerblue">**For finite MDP we can order policies through state value. Policy $$\pi$$ is better than policy $$\pi'$$ if $$\upsilon_{\pi}\ge\upsilon_{\pi'}$$ for all states $$s\inS$$**</span>

Last update: 18th of April, 2020

### Bellman optimality equation for value of state $$\upsilon_{\pi}$$


