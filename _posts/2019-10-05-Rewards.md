---
title: "Reward and Returns in Reinforcement Learning"
date: 2019-10-05
categories: [RL]
tags: [Reinforcement Learning, Theory]
excerpt: "What is reward and return? It is a foundation when introducing concept of value function"
mathjax: "true"
---

> <span style="color:dodgerblue">**Take away message from the note:**</span>
> * <span style="color:dodgerblue">**Reward is a response of an environment to the action at a signle time step $$t$$**</span>
> * <span style="color:dodgerblue">**Return is a sum of all rewards**</span>
> * <span style="color:dodgerblue">**The goal of RL agent is to learn a policy that maximize return**</span>

### What you can find in this note?
1. What is reward and return?
2. How they are used in Reinforcement Learning?

### What is reward and return?

In reinforcement learning framework, at each time step $$t$$ agent takes action and **environment responses back with special signal called reward** $$R_t\in\mathbb{R}$$. A reward is a simple number (value). Informally, the goal of the agent is to maximize the total amount of rewards it receives from the environment. Therefore it is not important to maximize imeediate reward but total sum of all rewards (cumulative reward) over long run. This concept can be stated in a followed way as **reward hypothesis**:

That all of what we mean by goals and purposes can be well thought as a **maximization of the expected value** of the cumulatvie sum of received scalar signal (called reward).

We can present a sequence of rewards received after time step $$t$$ as:
$$ G_t \doteq R_{t+1} + R_{t+2} + R_{t+3} + ... R_T$$

where $$T$$ is the final step. In reinformcement learning we want to maximize expected value of **retrun G_t**. In the above case the return is presented as a function where all rewards are summed up. This function is the simplest one. There might be other functions to translate indivdual rewards into return we want to maximimze.

 



