---
title: "Road Map of Learning of Reinforcement Learning"
date: 2019-08-21
categories: [RL]
tags: [Reinforcement Learning]
excerpt: "What are reasonable step in learning process of Reinforcement Learning"
mathjax: "true"
order: 1
classes: wide
---

So far I have covered following topics:
 * K-armed bandit problem (bandits problem). I have epxplained what is bandit problem and why it matters on the way to Reinforcement Learning. See [Bandit Problem](http://www.damiankolmas.com/rl/Bandit-problem/) note.
 * How action value can be used in general. This topic is covered in [Action Value - An Overivew](http://www.damiankolmas.com/rl/Action-value-method/) note
 * How action value can be estiamted. This topic is covered in [Estimating Value of Action](http://www.damiankolmas.com/rl/Estimating-value-of-action/#) note.
 * [Marcov Decission Process](http://www.damiankolmas.com/rl/Marcov-Decission-Process/) - the way to represent (dynamics of) environment
 * [Reward and Returns in Reinforcement Learning](http://www.damiankolmas.com/rl/Rewards/#) - sounds less important then it is in fact (in progress)

Next I will focus on following topics:
 * Value functions and policies (in progress)
 * Bellman Equations (first draft available)
 * Reinforcement Learning cheatsheet (in preparation of draft document)
 * Backup diagrams 
 * Dynamic Programming - a family of algorithms desing with assumption of full knowledge of the environment (MDP is priveded)
 * Monte Carlo methods
 * Temporal Difference Learning methods
   * SARSA, Q-learning and Expected SARSA
 * Generalized Policy Iteration
 * Review of major learning approaches (algorithms). Comparison of similarities and differetneces:
   * Dynamic Programming
   * Monte Carlo
   * Q-learning
   * SARSA and Expected Sarsa
 * Sample effificient learning - Dyna architecture for Planninig and Learning
 * Upper confidence bound - what is that in the context of reinforcement and why we need it to consider (what type of the tool is that so we need it)

Other topics are on the way as well...

The next one topic I am working on is **Returns and Episodes**:



